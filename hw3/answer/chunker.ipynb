{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunker: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from default import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the default solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [00:02<00:00, 459.66it/s]\n"
     ]
    }
   ],
   "source": [
    "chunker = LSTMTagger(os.path.join('data', 'train.txt.gz'), os.path.join('data', 'chunker'), '.tar')\n",
    "decoder_output = chunker.decode('data/input/dev.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the default output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 11672 phrases; correct: 8568.\n",
      "accuracy:  84.35%; (non-O)\n",
      "accuracy:  85.65%; precision:  73.41%; recall:  72.02%; FB1:  72.71\n",
      "             ADJP: precision:  36.49%; recall:  11.95%; FB1:  18.00  74\n",
      "             ADVP: precision:  71.36%; recall:  39.45%; FB1:  50.81  220\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               NP: precision:  70.33%; recall:  76.80%; FB1:  73.42  6811\n",
      "               PP: precision:  92.40%; recall:  87.14%; FB1:  89.69  2302\n",
      "              PRT: precision:  65.00%; recall:  57.78%; FB1:  61.18  40\n",
      "             SBAR: precision:  84.62%; recall:  41.77%; FB1:  55.93  117\n",
      "               VP: precision:  63.66%; recall:  58.25%; FB1:  60.83  2108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(73.40644276901988, 72.02420981842637, 72.70875763747455)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('data','reference','dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Write some beautiful documentation of your program here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some explanation of our code\n",
    "\n",
    "***chunker.py*** is the script that we get the best score.\n",
    "\n",
    "***chunkerBase.py*** is the script that we only implement the baseline method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the character level representation\n",
    "\n",
    "Concatenate to the word embedding input to the chunker RNN an input vector that is the character level representation of the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seperate the character level representations into three conditions:\n",
    "\n",
    "1. **len(word) == 1**\n",
    "\n",
    "    In this conidtion, only v1 is not all zeros while v2 and v3 only contain zeros.\n",
    "\n",
    "\n",
    "2. **len(word) == 2**\n",
    "    \n",
    "    In this condition, v1 and v3 have ones in their vectors and v2 has all zeros.\n",
    "\n",
    "\n",
    "3. **len(word) >= 3**\n",
    "\n",
    "    In this condition, v1, v2 and v3 all contain ones and zeros.\n",
    "    \n",
    "And then we create the character level representation for each word.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_char(seq, to_ix):\n",
    "    one_hot = []\n",
    "    length = len(string.printable)\n",
    "    for w in seq:\n",
    "        start = torch.zeros(length)\n",
    "        mid = torch.zeros(length)\n",
    "        end = torch.zeros(length)\n",
    "        if len(w) == 1:\n",
    "            start[to_ix[w]] += 1\n",
    "        elif len(w) == 2:\n",
    "            start[to_ix[w[0]]] += 1\n",
    "            end[to_ix[w[-1]]] += 1\n",
    "        else: # >= 3 letters\n",
    "            start[to_ix[w[0]]] += 1\n",
    "            end[to_ix[w[-1]]] += 1\n",
    "            for l in w[1:-1]:\n",
    "                mid[to_ix[l]] += 1\n",
    "        vector = torch.cat((start, mid, end), dim=-1)\n",
    "        one_hot.append(vector)\n",
    "    one_hot = torch.stack(one_hot)\n",
    "    return torch.tensor(one_hot, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a second RNN model\n",
    "\n",
    "Use a second RNN that takes as input the character level representation and use the hidden layer of this second RNN and concatenate with the word embedding to form the new input to the chunker RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecondRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim = 300, hidden_dim = 128, output_dim = 64, target_size = 22):\n",
    "        torch.manual_seed(1)\n",
    "        super(SecondRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, bidirectional=False)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden1 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.hidden2tag = nn.Linear(output_dim, target_size)\n",
    "\n",
    "    def forward(self, chars):\n",
    "        # print(chars.view(len(sentence), 1, -1).type())\n",
    "        chars = chars.float()\n",
    "        length = chars.shape[0]\n",
    "        lstm_out, _ = self.lstm(chars.view(length, 1, -1))\n",
    "        hidden_out = self.hidden1(lstm_out.view(length, -1))\n",
    "        tag_space = self.hidden2tag(hidden_out.view(length, -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do some analysis of the results. What ideas did you try? What worked and what did not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result summary\n",
    "\n",
    "**Implementing the baseline method gives us a dev score of 77.01555275325767.**\n",
    "\n",
    "**With a second RNN, we get a dev score of 79.95543819112065.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing the baseline method, we decide to use more useful information to concatenate with the word embedding to form the new input to the chunker RNN. \n",
    "\n",
    "So we decide to use Option 2, which is implementing a second RNN to get more useful information from the character level representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The second RNN has the following structure:**\n",
    "\n",
    "A **LSTM** takes as input the character level representation of size 300 and output a vector of size 128.\n",
    "\n",
    "**\"hidden1\"** layer is used to output a vector that will concatenate with the word embedding to form the new input to the chunker RNN.\n",
    "\n",
    "**\"hidden2tag\"** layer is the same as the hidden layer in the chunker RNN and is used to train the second RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SecondRNN(\n",
      "  (lstm): LSTM(300, 128)\n",
      "  (hidden1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (hidden2tag): Linear(in_features=64, out_features=22, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "RNN = SecondRNN()\n",
    "print(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use **tag_scores** as the result, which is the same as the chunker model, to train our model and we use **stochastic gradient descent** with a **learning rate of 0.02** as the optimizer. And we train the model with **20 epochs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.optimizer_rnn = optim.SGD(self.rnn.parameters(), lr=0.02)\n",
    "def train_RNN(self):\n",
    "    loss_function = nn.NLLLoss()\n",
    "\n",
    "    # Train a second RNN\n",
    "    self.rnn.train()\n",
    "    loss = float(\"inf\")\n",
    "    for epoch in range(20):\n",
    "        for sentence, tags in tqdm.tqdm(self.training_data):\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            self.rnn.zero_grad()\n",
    "\n",
    "            # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "            # Tensors of word indices.\n",
    "            sentence_in = prepare_sequence(sentence, self.word_to_ix, self.unk)\n",
    "            targets = prepare_sequence(tags, self.tag_to_ix, self.unk)\n",
    "            char_in = prepare_char(sentence, self.char_to_ix)\n",
    "            # Step 3. Run our forward pass.\n",
    "            rnn_scores = self.rnn(char_in)\n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            #  calling optimizer.step()\n",
    "            loss = loss_function(rnn_scores, targets)\n",
    "            loss.backward()\n",
    "            self.optimizer_rnn.step()\n",
    "\n",
    "        if epoch == self.epochs-1:\n",
    "            epoch_str = '' # last epoch so do not use epoch number in model filename\n",
    "        else:\n",
    "            epoch_str = str(epoch)\n",
    "        savernnfile = self.rnnfile + epoch_str + self.modelsuffix\n",
    "        print(\"saving model file: {}\".format(savernnfile), file=sys.stderr)\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.rnn.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer_rnn.state_dict()\n",
    "                }, savernnfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training our RNN model, we just get rid of the last layer, which is the **\"hidden2tag\"** layer, since we only need this layer to train our model. Then, we get the output of the second last layer, which is the **\"hidden1\"** layer. This layer will output a vector of **size 64** which is used to concatenate with the word embedding to form the new input to the chunker RNN. Thus, we get a input of **size 192 (128 + 64)** to the chunker RNN. \n",
    "\n",
    "And then we train the chunker model with the hyperparameters used in the default solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following is the new structure of the chunker model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMTaggerModel(\n",
      "  (word_embeddings): Embedding(9675, 128)\n",
      "  (lstm): LSTM(192, 64)\n",
      "  (hidden2tag): Linear(in_features=64, out_features=22, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from chunker import *\n",
    "import os\n",
    "chunker = LSTMTagger(os.path.join(os.path.dirname(os.getcwd()), 'data', 'train.txt.gz'), os.path.join(os.path.dirname(os.getcwd()), 'data', 'chunker'), os.path.join(os.path.dirname(os.getcwd()), 'data', 'rnn'), '.tar')\n",
    "print(chunker.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of results between only baseline and baseline + second RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of the baseline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunkerBase import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1027 [00:00<?, ?it/s]/home/zerono614/Desktop/nlpclass-1207-g-red/hw3/answer/chunkerBase.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(one_hot, dtype=torch.long)\n",
      "100%|██████████| 1027/1027 [00:02<00:00, 343.76it/s]\n"
     ]
    }
   ],
   "source": [
    "chunker = LSTMTagger(os.path.join(os.path.dirname(os.getcwd()), 'data', 'train.txt.gz'), os.path.join(os.path.dirname(os.getcwd()), 'data', 'chunkerBase'), '.tar')\n",
    "decoder_output = chunker.decode(os.path.join(os.path.dirname(os.getcwd()), 'data/input/dev.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 11894 phrases; correct: 9161.\n",
      "accuracy:  86.83%; (non-O)\n",
      "accuracy:  87.82%; precision:  77.02%; recall:  77.01%; FB1:  77.02\n",
      "             ADJP: precision:  46.07%; recall:  18.14%; FB1:  26.03  89\n",
      "             ADVP: precision:  66.79%; recall:  46.48%; FB1:  54.81  277\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               NP: precision:  75.30%; recall:  80.28%; FB1:  77.71  6649\n",
      "               PP: precision:  91.55%; recall:  88.37%; FB1:  89.93  2356\n",
      "              PRT: precision:  69.44%; recall:  55.56%; FB1:  61.73  36\n",
      "             SBAR: precision:  85.60%; recall:  45.15%; FB1:  59.12  125\n",
      "               VP: precision:  69.39%; recall:  71.14%; FB1:  70.25  2362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(77.02202791323356, 77.00907868190988, 77.01555275325767)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join(os.path.dirname(os.getcwd()), 'data','reference','dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of baseline + second RNN\n",
    "\n",
    "With the second RNN we get a dev score of 79.95543819112065."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunker import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1027 [00:00<?, ?it/s]/home/zerono614/Desktop/nlpclass-1207-g-red/hw3/answer/chunker.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(one_hot, dtype=torch.long)\n",
      "100%|██████████| 1027/1027 [00:05<00:00, 200.94it/s]\n"
     ]
    }
   ],
   "source": [
    "chunker = LSTMTagger(os.path.join(os.path.dirname(os.getcwd()), 'data', 'train.txt.gz'), os.path.join(os.path.dirname(os.getcwd()), 'data', 'chunker'), os.path.join(os.path.dirname(os.getcwd()), 'data', 'rnn'), '.tar')\n",
    "decoder_output = chunker.decode(os.path.join(os.path.dirname(os.getcwd()), 'data/input/dev.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 12340 phrases; correct: 9689.\n",
      "accuracy:  88.33%; (non-O)\n",
      "accuracy:  89.30%; precision:  78.52%; recall:  81.45%; FB1:  79.96\n",
      "             ADJP: precision:  45.69%; recall:  23.45%; FB1:  30.99  116\n",
      "             ADVP: precision:  61.05%; recall:  55.53%; FB1:  58.16  362\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               NP: precision:  78.01%; recall:  84.14%; FB1:  80.96  6727\n",
      "               PP: precision:  91.42%; recall:  89.96%; FB1:  90.69  2402\n",
      "              PRT: precision:  71.05%; recall:  60.00%; FB1:  65.06  38\n",
      "             SBAR: precision:  77.56%; recall:  51.05%; FB1:  61.58  156\n",
      "               VP: precision:  71.80%; recall:  79.12%; FB1:  75.28  2539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(78.51701782820098, 81.44754539340954, 79.95543819112065)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join(os.path.dirname(os.getcwd()), 'data','reference','dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
